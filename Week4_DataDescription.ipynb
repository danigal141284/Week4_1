{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Science Capstone - Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the definition of the problem, factors that will influence the final decision are:\n",
    "* **1. number of existing Venues** from every category in each neighborhood, within a certain radius from the center of the neighborhood\n",
    "\n",
    "* **2. number of existing Pubs** within the same radius, as a subcategory of \"Bars\"\n",
    "\n",
    "* **3. house pricing in each potential neighborhood**\n",
    "\n",
    "* **4. distance of the neighborhood from city center** is a plus, important but not decisive\n",
    "\n",
    "\n",
    "The following data sources will be needed to extract/generate the required information:\n",
    "\n",
    "* **1. \"Anexo: Barrios de Montevideo\" Wikipedia page**, to extract the name and other information of the 62 neighborhoods of the capital of Uruguay, via website scraping with Beautiful Soup. https://es.wikipedia.org/wiki/Anexo:Barrios_de_Montevideo\n",
    "\n",
    "* **2. Average house sale prices from each neighborhood**. I found information of the year 2017 and before from **Instituto Nacional de Estadistica** http://www.ine.gub.uy/ and set-up my own data table. For those neighborhoods in which no data was reported, the average of neighborhoods with the **same borough code** was assigned as the corresponding value for the missing data. When there was no data for 2017, I took the first previous value and applied linear extrapolation, by considering the full set of values from a neighborhood where all the information was complete. http://www.ine.gub.uy/c/document_library/get_file?uuid=dc2d978d-7027-4370-b2de-2f70c4d4ede8&groupId=10181\n",
    "\n",
    "* **3. Coordinates of the center of each neighborhood** are not included in the Wikipedia page, so I used **Google Maps geocoding API** https://cloud.google.com/maps-platform/maps/?apis=maps to get the list of (latitude, longitude) of the 62 rows. To center the Folium maps, I used Google Maps API geocoding to get the coordinates of a well known Montevideo location: bus terminal called **\"Terminal Tres Cruces\"**, as \"Montevideo center\".\n",
    "\n",
    "* **4. Number and categories of the Venues** within a certain radius from each neighborhood center, by using the **Foursquare API**. I filtered and dropped every neighborhood with less than 50 venues to keep only those neighborhoods with  enough commercial activity as to consider establishing a business there. This information is grouped to find the most common venues and the **cluster the potential neighborhoods**. Finally, for those potential neighborhods, I explored the **number of Bars** and then filtered specifically those which are **Pubs**. \n",
    "\n",
    "* **5. A .json file with the spacial coordinates of every Montevideo neighborhood** with the purpose of building  a Choropleth Map with \"average housing sale prices\" (HSP) as the parameter. I found that file from a Github repository  https://github.com/vierja/geojson_montevideo/blob/master/barrios.geojson and it said the original source was https://catalogodatos.gub.uy, but the file was deleted from the main source."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
